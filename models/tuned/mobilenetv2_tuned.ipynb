{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yash\\Documents\\Development\\Projects\\final_year\\env\\Lib\\site-packages\\albumentations\\__init__.py:24: UserWarning: A new version of Albumentations is available: 1.4.23 (you have 1.4.22). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from utils.dataset_loader import load_datasets\n",
    "from utils.model_utils import initialize_model\n",
    "from utils.train_utils import train_model\n",
    "from utils.metrics import evaluate_model\n",
    "from utils.visualization import plot_training, plot_confusion_matrix\n",
    "import optuna\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"[INFO] Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"outputs/models\", exist_ok=True)\n",
    "os.makedirs(\"outputs/plots\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loading datasets...\n",
      "[INFO] Datasets loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] Loading datasets...\")\n",
    "train_loader, val_loader, test_loader = load_datasets(\n",
    "    \"wildfire_dataset_scaled\", batch_size=32, augmentation=\"augmented\"\n",
    ")\n",
    "print(\"[INFO] Datasets loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    print(f\"[DEBUG] Starting trial {trial.number}...\")\n",
    "\n",
    "    # Hyperparameter suggestions\n",
    "    lr = trial.suggest_float(\"lr\", 1e-5, 1e-2, log=True)\n",
    "    weight_decay = trial.suggest_float(\"weight_decay\", 1e-5, 1e-3, log=True)\n",
    "    optimizer_name = trial.suggest_categorical(\"optimizer\", [\"Adam\", \"SGD\", \"AdamW\"])\n",
    "    print(f\"[DEBUG] Suggested hyperparameters: lr={lr}, weight_decay={weight_decay}, optimizer={optimizer_name}\")\n",
    "\n",
    "    # Initialize model\n",
    "    print(\"[DEBUG] Initializing mobilenet_v2 model...\")\n",
    "    model = initialize_model(\"mobilenet_v2\", num_classes=2, pretrained=True, freeze_all=False, unfreeze_last_n=2)\n",
    "    model.to(device)\n",
    "\n",
    "    # Optimizer setup\n",
    "    print(\"[DEBUG] Setting up optimizer...\")\n",
    "    if optimizer_name == \"Adam\":\n",
    "        optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    elif optimizer_name == \"SGD\":\n",
    "        optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=weight_decay)\n",
    "    elif optimizer_name == \"AdamW\":\n",
    "        optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "    # Scheduler\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"max\", patience=3, factor=0.5)\n",
    "\n",
    "    # Loss function\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Train the model\n",
    "    print(\"[INFO] Starting model training...\")\n",
    "    save_path = \"outputs/models/mobilenet_v2_trial_best.pth\"\n",
    "    history = train_model(\n",
    "        model=model,\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        criterion=criterion,\n",
    "        optimizer=optimizer,\n",
    "        scheduler=scheduler,\n",
    "        device=device,\n",
    "        save_path=save_path,\n",
    "        early_stop_patience=5,\n",
    "        monitor_metric=\"val_recall\",\n",
    "    )\n",
    "    print(\"[INFO] Training completed!\")\n",
    "\n",
    "    # Return validation recall\n",
    "    val_recall = history[\"val_recall\"][-1]\n",
    "    print(f\"[INFO] Trial {trial.number} - Final Validation Recall: {val_recall:.4f}\")\n",
    "    return val_recall\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-18 18:56:56,860] A new study created in memory with name: no-name-8cf8f440-3eef-4f42-8398-207c388e5ca1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Running hyperparameter optimization...\n",
      "[DEBUG] Starting trial 0...\n",
      "[DEBUG] Suggested hyperparameters: lr=0.002060405581092832, weight_decay=6.102976271899184e-05, optimizer=Adam\n",
      "[DEBUG] Initializing mobilenet_v2 model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yash\\Documents\\Development\\Projects\\final_year\\env\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Yash\\Documents\\Development\\Projects\\final_year\\env\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "C:\\Users\\Yash\\Documents\\Development\\Projects\\final_year\\env\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Setting up optimizer...\n",
      "[INFO] Starting model training...\n",
      "\n",
      "Starting training...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1]: Train Loss: 0.5522, Train Acc: 0.7515 | Val Loss: 0.4618, Val Acc: 0.7736, Val Recall: 0.9024, Val F1: 0.8299\n",
      "[INFO] Best model saved with val_recall: 0.9024\n",
      "[INFO] Learning rate adjusted to: 0.002060\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2]: Train Loss: 0.4265, Train Acc: 0.8087 | Val Loss: 0.4275, Val Acc: 0.8134, Val Recall: 0.8902, Val F1: 0.8538\n",
      "[INFO] No improvement in val_recall. Patience: 1/5\n",
      "[INFO] Learning rate adjusted to: 0.002060\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3]: Train Loss: 0.3387, Train Acc: 0.8532 | Val Loss: 0.3804, Val Acc: 0.8159, Val Recall: 0.9431, Val F1: 0.8625\n",
      "[INFO] Best model saved with val_recall: 0.9431\n",
      "[INFO] Learning rate adjusted to: 0.002060\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4]: Train Loss: 0.3406, Train Acc: 0.8585 | Val Loss: 0.4024, Val Acc: 0.8234, Val Recall: 0.9024, Val F1: 0.8621\n",
      "[INFO] No improvement in val_recall. Patience: 1/5\n",
      "[INFO] Learning rate adjusted to: 0.002060\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5]: Train Loss: 0.3288, Train Acc: 0.8569 | Val Loss: 0.3233, Val Acc: 0.8781, Val Recall: 0.9187, Val F1: 0.9022\n",
      "[INFO] No improvement in val_recall. Patience: 2/5\n",
      "[INFO] Learning rate adjusted to: 0.002060\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6]: Train Loss: 0.3212, Train Acc: 0.8691 | Val Loss: 0.3701, Val Acc: 0.8682, Val Recall: 0.9228, Val F1: 0.8955\n",
      "[INFO] No improvement in val_recall. Patience: 3/5\n",
      "[INFO] Learning rate adjusted to: 0.002060\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7]: Train Loss: 0.2783, Train Acc: 0.8866 | Val Loss: 0.3106, Val Acc: 0.8756, Val Recall: 0.9065, Val F1: 0.8992\n",
      "[INFO] No improvement in val_recall. Patience: 4/5\n",
      "[INFO] Learning rate adjusted to: 0.001030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8]: Train Loss: 0.2544, Train Acc: 0.8861 | Val Loss: 0.2871, Val Acc: 0.8930, Val Recall: 0.9512, Val F1: 0.9159\n",
      "[INFO] Best model saved with val_recall: 0.9512\n",
      "[INFO] Learning rate adjusted to: 0.001030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9]: Train Loss: 0.2215, Train Acc: 0.9157 | Val Loss: 0.2792, Val Acc: 0.9005, Val Recall: 0.9187, Val F1: 0.9187\n",
      "[INFO] No improvement in val_recall. Patience: 1/5\n",
      "[INFO] Learning rate adjusted to: 0.001030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10]: Train Loss: 0.2101, Train Acc: 0.9115 | Val Loss: 0.3486, Val Acc: 0.8905, Val Recall: 0.9146, Val F1: 0.9109\n",
      "[INFO] No improvement in val_recall. Patience: 2/5\n",
      "[INFO] Learning rate adjusted to: 0.001030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11]: Train Loss: 0.2071, Train Acc: 0.9200 | Val Loss: 0.3993, Val Acc: 0.8483, Val Recall: 0.8740, Val F1: 0.8758\n",
      "[INFO] No improvement in val_recall. Patience: 3/5\n",
      "[INFO] Learning rate adjusted to: 0.001030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12]: Train Loss: 0.1992, Train Acc: 0.9157 | Val Loss: 0.3470, Val Acc: 0.8756, Val Recall: 0.8943, Val F1: 0.8980\n",
      "[INFO] No improvement in val_recall. Patience: 4/5\n",
      "[INFO] Learning rate adjusted to: 0.000515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13]: Train Loss: 0.1652, Train Acc: 0.9343 | Val Loss: 0.2765, Val Acc: 0.8905, Val Recall: 0.9593, Val F1: 0.9147\n",
      "[INFO] Best model saved with val_recall: 0.9593\n",
      "[INFO] Learning rate adjusted to: 0.000515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14]: Train Loss: 0.1465, Train Acc: 0.9438 | Val Loss: 0.3851, Val Acc: 0.8955, Val Recall: 0.9309, Val F1: 0.9160\n",
      "[INFO] No improvement in val_recall. Patience: 1/5\n",
      "[INFO] Learning rate adjusted to: 0.000515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15]: Train Loss: 0.1458, Train Acc: 0.9422 | Val Loss: 0.3095, Val Acc: 0.8955, Val Recall: 0.9146, Val F1: 0.9146\n",
      "[INFO] No improvement in val_recall. Patience: 2/5\n",
      "[INFO] Learning rate adjusted to: 0.000515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16]: Train Loss: 0.1287, Train Acc: 0.9565 | Val Loss: 0.3132, Val Acc: 0.8930, Val Recall: 0.9065, Val F1: 0.9121\n",
      "[INFO] No improvement in val_recall. Patience: 3/5\n",
      "[INFO] Learning rate adjusted to: 0.000515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17]: Train Loss: 0.1550, Train Acc: 0.9391 | Val Loss: 0.3431, Val Acc: 0.8806, Val Recall: 0.9309, Val F1: 0.9051\n",
      "[INFO] No improvement in val_recall. Patience: 4/5\n",
      "[INFO] Learning rate adjusted to: 0.000258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-18 18:59:49,071] Trial 0 finished with value: 0.9349593495934959 and parameters: {'lr': 0.002060405581092832, 'weight_decay': 6.102976271899184e-05, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.9349593495934959.\n",
      "C:\\Users\\Yash\\Documents\\Development\\Projects\\final_year\\env\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Yash\\Documents\\Development\\Projects\\final_year\\env\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "C:\\Users\\Yash\\Documents\\Development\\Projects\\final_year\\env\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18]: Train Loss: 0.1421, Train Acc: 0.9523 | Val Loss: 0.3395, Val Acc: 0.8980, Val Recall: 0.9350, Val F1: 0.9182\n",
      "[INFO] No improvement in val_recall. Patience: 5/5\n",
      "[INFO] Learning rate adjusted to: 0.000258\n",
      "[INFO] Training stopped after 18 epochs.\n",
      "\n",
      "[INFO] Training completed!\n",
      "[INFO] Trial 0 - Final Validation Recall: 0.9350\n",
      "[DEBUG] Starting trial 1...\n",
      "[DEBUG] Suggested hyperparameters: lr=0.004953863968144643, weight_decay=2.8568976927702252e-05, optimizer=SGD\n",
      "[DEBUG] Initializing mobilenet_v2 model...\n",
      "[DEBUG] Setting up optimizer...\n",
      "[INFO] Starting model training...\n",
      "\n",
      "Starting training...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1]: Train Loss: 0.4559, Train Acc: 0.7864 | Val Loss: 0.4305, Val Acc: 0.8209, Val Recall: 0.8008, Val F1: 0.8455\n",
      "[INFO] Best model saved with val_recall: 0.8008\n",
      "[INFO] Learning rate adjusted to: 0.004954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2]: Train Loss: 0.3636, Train Acc: 0.8500 | Val Loss: 0.3689, Val Acc: 0.8284, Val Recall: 0.8618, Val F1: 0.8600\n",
      "[INFO] Best model saved with val_recall: 0.8618\n",
      "[INFO] Learning rate adjusted to: 0.004954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3]: Train Loss: 0.3216, Train Acc: 0.8638 | Val Loss: 0.3939, Val Acc: 0.8433, Val Recall: 0.9634, Val F1: 0.8827\n",
      "[INFO] Best model saved with val_recall: 0.9634\n",
      "[INFO] Learning rate adjusted to: 0.004954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4]: Train Loss: 0.2397, Train Acc: 0.9110 | Val Loss: 0.3291, Val Acc: 0.8632, Val Recall: 0.9146, Val F1: 0.8911\n",
      "[INFO] No improvement in val_recall. Patience: 1/5\n",
      "[INFO] Learning rate adjusted to: 0.004954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5]: Train Loss: 0.2298, Train Acc: 0.9099 | Val Loss: 0.4088, Val Acc: 0.8333, Val Recall: 0.9065, Val F1: 0.8694\n",
      "[INFO] No improvement in val_recall. Patience: 2/5\n",
      "[INFO] Learning rate adjusted to: 0.004954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6]: Train Loss: 0.1925, Train Acc: 0.9232 | Val Loss: 0.3250, Val Acc: 0.8781, Val Recall: 0.9472, Val F1: 0.9049\n",
      "[INFO] No improvement in val_recall. Patience: 3/5\n",
      "[INFO] Learning rate adjusted to: 0.004954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7]: Train Loss: 0.1821, Train Acc: 0.9300 | Val Loss: 0.3354, Val Acc: 0.8856, Val Recall: 0.9756, Val F1: 0.9125\n",
      "[INFO] Best model saved with val_recall: 0.9756\n",
      "[INFO] Learning rate adjusted to: 0.004954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8]: Train Loss: 0.1327, Train Acc: 0.9518 | Val Loss: 0.2843, Val Acc: 0.9080, Val Recall: 0.9593, Val F1: 0.9273\n",
      "[INFO] No improvement in val_recall. Patience: 1/5\n",
      "[INFO] Learning rate adjusted to: 0.004954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9]: Train Loss: 0.1522, Train Acc: 0.9391 | Val Loss: 0.3663, Val Acc: 0.8781, Val Recall: 0.9350, Val F1: 0.9037\n",
      "[INFO] No improvement in val_recall. Patience: 2/5\n",
      "[INFO] Learning rate adjusted to: 0.004954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10]: Train Loss: 0.1426, Train Acc: 0.9459 | Val Loss: 0.3288, Val Acc: 0.8856, Val Recall: 0.9472, Val F1: 0.9102\n",
      "[INFO] No improvement in val_recall. Patience: 3/5\n",
      "[INFO] Learning rate adjusted to: 0.004954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11]: Train Loss: 0.1122, Train Acc: 0.9597 | Val Loss: 0.3050, Val Acc: 0.8930, Val Recall: 0.9553, Val F1: 0.9162\n",
      "[INFO] No improvement in val_recall. Patience: 4/5\n",
      "[INFO] Learning rate adjusted to: 0.002477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-18 19:01:43,262] Trial 1 finished with value: 0.9552845528455285 and parameters: {'lr': 0.004953863968144643, 'weight_decay': 2.8568976927702252e-05, 'optimizer': 'SGD'}. Best is trial 1 with value: 0.9552845528455285.\n",
      "C:\\Users\\Yash\\Documents\\Development\\Projects\\final_year\\env\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Yash\\Documents\\Development\\Projects\\final_year\\env\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "C:\\Users\\Yash\\Documents\\Development\\Projects\\final_year\\env\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12]: Train Loss: 0.0766, Train Acc: 0.9698 | Val Loss: 0.2779, Val Acc: 0.9154, Val Recall: 0.9553, Val F1: 0.9325\n",
      "[INFO] No improvement in val_recall. Patience: 5/5\n",
      "[INFO] Learning rate adjusted to: 0.002477\n",
      "[INFO] Training stopped after 12 epochs.\n",
      "\n",
      "[INFO] Training completed!\n",
      "[INFO] Trial 1 - Final Validation Recall: 0.9553\n",
      "[DEBUG] Starting trial 2...\n",
      "[DEBUG] Suggested hyperparameters: lr=0.0008317518596716266, weight_decay=0.0001379618760334803, optimizer=SGD\n",
      "[DEBUG] Initializing mobilenet_v2 model...\n",
      "[DEBUG] Setting up optimizer...\n",
      "[INFO] Starting model training...\n",
      "\n",
      "Starting training...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1]: Train Loss: 0.4790, Train Acc: 0.7530 | Val Loss: 0.3723, Val Acc: 0.8308, Val Recall: 0.9431, Val F1: 0.8722\n",
      "[INFO] Best model saved with val_recall: 0.9431\n",
      "[INFO] Learning rate adjusted to: 0.000832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2]: Train Loss: 0.3197, Train Acc: 0.8537 | Val Loss: 0.3389, Val Acc: 0.8433, Val Recall: 0.9065, Val F1: 0.8762\n",
      "[INFO] No improvement in val_recall. Patience: 1/5\n",
      "[INFO] Learning rate adjusted to: 0.000832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3]: Train Loss: 0.2499, Train Acc: 0.8977 | Val Loss: 0.2982, Val Acc: 0.8756, Val Recall: 0.9431, Val F1: 0.9027\n",
      "[INFO] No improvement in val_recall. Patience: 2/5\n",
      "[INFO] Learning rate adjusted to: 0.000832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4]: Train Loss: 0.2135, Train Acc: 0.9062 | Val Loss: 0.3461, Val Acc: 0.8731, Val Recall: 0.9634, Val F1: 0.9029\n",
      "[INFO] Best model saved with val_recall: 0.9634\n",
      "[INFO] Learning rate adjusted to: 0.000832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5]: Train Loss: 0.2013, Train Acc: 0.9194 | Val Loss: 0.3114, Val Acc: 0.8657, Val Recall: 0.9350, Val F1: 0.8949\n",
      "[INFO] No improvement in val_recall. Patience: 1/5\n",
      "[INFO] Learning rate adjusted to: 0.000832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6]: Train Loss: 0.1667, Train Acc: 0.9375 | Val Loss: 0.2844, Val Acc: 0.9005, Val Recall: 0.9431, Val F1: 0.9206\n",
      "[INFO] No improvement in val_recall. Patience: 2/5\n",
      "[INFO] Learning rate adjusted to: 0.000832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7]: Train Loss: 0.1511, Train Acc: 0.9401 | Val Loss: 0.3035, Val Acc: 0.8781, Val Recall: 0.9309, Val F1: 0.9034\n",
      "[INFO] No improvement in val_recall. Patience: 3/5\n",
      "[INFO] Learning rate adjusted to: 0.000832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8]: Train Loss: 0.1504, Train Acc: 0.9385 | Val Loss: 0.2867, Val Acc: 0.8905, Val Recall: 0.9187, Val F1: 0.9113\n",
      "[INFO] No improvement in val_recall. Patience: 4/5\n",
      "[INFO] Learning rate adjusted to: 0.000416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-18 19:03:13,519] Trial 2 finished with value: 0.9390243902439024 and parameters: {'lr': 0.0008317518596716266, 'weight_decay': 0.0001379618760334803, 'optimizer': 'SGD'}. Best is trial 1 with value: 0.9552845528455285.\n",
      "C:\\Users\\Yash\\Documents\\Development\\Projects\\final_year\\env\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Yash\\Documents\\Development\\Projects\\final_year\\env\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "C:\\Users\\Yash\\Documents\\Development\\Projects\\final_year\\env\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9]: Train Loss: 0.1161, Train Acc: 0.9565 | Val Loss: 0.2800, Val Acc: 0.8881, Val Recall: 0.9390, Val F1: 0.9112\n",
      "[INFO] No improvement in val_recall. Patience: 5/5\n",
      "[INFO] Learning rate adjusted to: 0.000416\n",
      "[INFO] Training stopped after 9 epochs.\n",
      "\n",
      "[INFO] Training completed!\n",
      "[INFO] Trial 2 - Final Validation Recall: 0.9390\n",
      "[DEBUG] Starting trial 3...\n",
      "[DEBUG] Suggested hyperparameters: lr=0.0007919201032548925, weight_decay=0.0004957920811426165, optimizer=AdamW\n",
      "[DEBUG] Initializing mobilenet_v2 model...\n",
      "[DEBUG] Setting up optimizer...\n",
      "[INFO] Starting model training...\n",
      "\n",
      "Starting training...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1]: Train Loss: 0.4782, Train Acc: 0.7891 | Val Loss: 0.4051, Val Acc: 0.8408, Val Recall: 0.8902, Val F1: 0.8725\n",
      "[INFO] Best model saved with val_recall: 0.8902\n",
      "[INFO] Learning rate adjusted to: 0.000792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2]: Train Loss: 0.3255, Train Acc: 0.8585 | Val Loss: 0.3016, Val Acc: 0.8881, Val Recall: 0.9390, Val F1: 0.9112\n",
      "[INFO] Best model saved with val_recall: 0.9390\n",
      "[INFO] Learning rate adjusted to: 0.000792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3]: Train Loss: 0.2702, Train Acc: 0.8877 | Val Loss: 0.3567, Val Acc: 0.8657, Val Recall: 0.9065, Val F1: 0.8920\n",
      "[INFO] No improvement in val_recall. Patience: 1/5\n",
      "[INFO] Learning rate adjusted to: 0.000792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4]: Train Loss: 0.2486, Train Acc: 0.8993 | Val Loss: 0.3431, Val Acc: 0.8607, Val Recall: 0.9268, Val F1: 0.8906\n",
      "[INFO] No improvement in val_recall. Patience: 2/5\n",
      "[INFO] Learning rate adjusted to: 0.000792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5]: Train Loss: 0.2547, Train Acc: 0.9025 | Val Loss: 0.2970, Val Acc: 0.8831, Val Recall: 0.9065, Val F1: 0.9047\n",
      "[INFO] No improvement in val_recall. Patience: 3/5\n",
      "[INFO] Learning rate adjusted to: 0.000792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6]: Train Loss: 0.2374, Train Acc: 0.9062 | Val Loss: 0.3590, Val Acc: 0.8806, Val Recall: 0.9512, Val F1: 0.9070\n",
      "[INFO] Best model saved with val_recall: 0.9512\n",
      "[INFO] Learning rate adjusted to: 0.000792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7]: Train Loss: 0.1983, Train Acc: 0.9263 | Val Loss: 0.4599, Val Acc: 0.8657, Val Recall: 0.8496, Val F1: 0.8856\n",
      "[INFO] No improvement in val_recall. Patience: 1/5\n",
      "[INFO] Learning rate adjusted to: 0.000792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8]: Train Loss: 0.2098, Train Acc: 0.9168 | Val Loss: 0.3542, Val Acc: 0.8706, Val Recall: 0.8984, Val F1: 0.8947\n",
      "[INFO] No improvement in val_recall. Patience: 2/5\n",
      "[INFO] Learning rate adjusted to: 0.000792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9]: Train Loss: 0.1748, Train Acc: 0.9332 | Val Loss: 0.4102, Val Acc: 0.8706, Val Recall: 0.9634, Val F1: 0.9011\n",
      "[INFO] Best model saved with val_recall: 0.9634\n",
      "[INFO] Learning rate adjusted to: 0.000792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10]: Train Loss: 0.2267, Train Acc: 0.9089 | Val Loss: 0.3081, Val Acc: 0.8955, Val Recall: 0.9268, Val F1: 0.9157\n",
      "[INFO] No improvement in val_recall. Patience: 1/5\n",
      "[INFO] Learning rate adjusted to: 0.000792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11]: Train Loss: 0.1647, Train Acc: 0.9380 | Val Loss: 0.3697, Val Acc: 0.8682, Val Recall: 0.8862, Val F1: 0.8916\n",
      "[INFO] No improvement in val_recall. Patience: 2/5\n",
      "[INFO] Learning rate adjusted to: 0.000792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12]: Train Loss: 0.1805, Train Acc: 0.9263 | Val Loss: 0.3657, Val Acc: 0.8905, Val Recall: 0.9390, Val F1: 0.9130\n",
      "[INFO] No improvement in val_recall. Patience: 3/5\n",
      "[INFO] Learning rate adjusted to: 0.000792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13]: Train Loss: 0.1448, Train Acc: 0.9422 | Val Loss: 0.4298, Val Acc: 0.8881, Val Recall: 0.8943, Val F1: 0.9072\n",
      "[INFO] No improvement in val_recall. Patience: 4/5\n",
      "[INFO] Learning rate adjusted to: 0.000396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-18 19:05:31,714] Trial 3 finished with value: 0.9308943089430894 and parameters: {'lr': 0.0007919201032548925, 'weight_decay': 0.0004957920811426165, 'optimizer': 'AdamW'}. Best is trial 1 with value: 0.9552845528455285.\n",
      "C:\\Users\\Yash\\Documents\\Development\\Projects\\final_year\\env\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Yash\\Documents\\Development\\Projects\\final_year\\env\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "C:\\Users\\Yash\\Documents\\Development\\Projects\\final_year\\env\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14]: Train Loss: 0.1442, Train Acc: 0.9518 | Val Loss: 0.2865, Val Acc: 0.9104, Val Recall: 0.9309, Val F1: 0.9271\n",
      "[INFO] No improvement in val_recall. Patience: 5/5\n",
      "[INFO] Learning rate adjusted to: 0.000396\n",
      "[INFO] Training stopped after 14 epochs.\n",
      "\n",
      "[INFO] Training completed!\n",
      "[INFO] Trial 3 - Final Validation Recall: 0.9309\n",
      "[DEBUG] Starting trial 4...\n",
      "[DEBUG] Suggested hyperparameters: lr=1.9840448671922433e-05, weight_decay=0.0002669971190380106, optimizer=SGD\n",
      "[DEBUG] Initializing mobilenet_v2 model...\n",
      "[DEBUG] Setting up optimizer...\n",
      "[INFO] Starting model training...\n",
      "\n",
      "Starting training...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1]: Train Loss: 0.6975, Train Acc: 0.5390 | Val Loss: 0.6643, Val Acc: 0.6169, Val Recall: 0.8699, Val F1: 0.7354\n",
      "[INFO] Best model saved with val_recall: 0.8699\n",
      "[INFO] Learning rate adjusted to: 0.000020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2]: Train Loss: 0.6403, Train Acc: 0.6237 | Val Loss: 0.6305, Val Acc: 0.6517, Val Recall: 0.9187, Val F1: 0.7635\n",
      "[INFO] Best model saved with val_recall: 0.9187\n",
      "[INFO] Learning rate adjusted to: 0.000020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3]: Train Loss: 0.6194, Train Acc: 0.6444 | Val Loss: 0.6107, Val Acc: 0.6468, Val Recall: 0.8984, Val F1: 0.7568\n",
      "[INFO] No improvement in val_recall. Patience: 1/5\n",
      "[INFO] Learning rate adjusted to: 0.000020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4]: Train Loss: 0.5905, Train Acc: 0.6847 | Val Loss: 0.5890, Val Acc: 0.6692, Val Recall: 0.8902, Val F1: 0.7671\n",
      "[INFO] No improvement in val_recall. Patience: 2/5\n",
      "[INFO] Learning rate adjusted to: 0.000020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5]: Train Loss: 0.5784, Train Acc: 0.6895 | Val Loss: 0.5677, Val Acc: 0.7139, Val Recall: 0.8943, Val F1: 0.7928\n",
      "[INFO] No improvement in val_recall. Patience: 3/5\n",
      "[INFO] Learning rate adjusted to: 0.000020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6]: Train Loss: 0.5558, Train Acc: 0.7244 | Val Loss: 0.5615, Val Acc: 0.6940, Val Recall: 0.8902, Val F1: 0.7807\n",
      "[INFO] No improvement in val_recall. Patience: 4/5\n",
      "[INFO] Learning rate adjusted to: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-18 19:06:41,960] Trial 4 finished with value: 0.8821138211382114 and parameters: {'lr': 1.9840448671922433e-05, 'weight_decay': 0.0002669971190380106, 'optimizer': 'SGD'}. Best is trial 1 with value: 0.9552845528455285.\n",
      "C:\\Users\\Yash\\Documents\\Development\\Projects\\final_year\\env\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Yash\\Documents\\Development\\Projects\\final_year\\env\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "C:\\Users\\Yash\\Documents\\Development\\Projects\\final_year\\env\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7]: Train Loss: 0.5431, Train Acc: 0.7271 | Val Loss: 0.5442, Val Acc: 0.7114, Val Recall: 0.8821, Val F1: 0.7891\n",
      "[INFO] No improvement in val_recall. Patience: 5/5\n",
      "[INFO] Learning rate adjusted to: 0.000010\n",
      "[INFO] Training stopped after 7 epochs.\n",
      "\n",
      "[INFO] Training completed!\n",
      "[INFO] Trial 4 - Final Validation Recall: 0.8821\n",
      "[DEBUG] Starting trial 5...\n",
      "[DEBUG] Suggested hyperparameters: lr=0.0032323398781456242, weight_decay=3.336140015073433e-05, optimizer=SGD\n",
      "[DEBUG] Initializing mobilenet_v2 model...\n",
      "[DEBUG] Setting up optimizer...\n",
      "[INFO] Starting model training...\n",
      "\n",
      "Starting training...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1]: Train Loss: 0.5029, Train Acc: 0.7520 | Val Loss: 0.3943, Val Acc: 0.8333, Val Recall: 0.9553, Val F1: 0.8752\n",
      "[INFO] Best model saved with val_recall: 0.9553\n",
      "[INFO] Learning rate adjusted to: 0.003232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2]: Train Loss: 0.2906, Train Acc: 0.8760 | Val Loss: 0.3252, Val Acc: 0.8557, Val Recall: 0.8984, Val F1: 0.8840\n",
      "[INFO] No improvement in val_recall. Patience: 1/5\n",
      "[INFO] Learning rate adjusted to: 0.003232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3]: Train Loss: 0.2718, Train Acc: 0.8850 | Val Loss: 0.2977, Val Acc: 0.8905, Val Recall: 0.9187, Val F1: 0.9113\n",
      "[INFO] No improvement in val_recall. Patience: 2/5\n",
      "[INFO] Learning rate adjusted to: 0.003232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4]: Train Loss: 0.2108, Train Acc: 0.9152 | Val Loss: 0.3070, Val Acc: 0.8582, Val Recall: 0.9309, Val F1: 0.8893\n",
      "[INFO] No improvement in val_recall. Patience: 3/5\n",
      "[INFO] Learning rate adjusted to: 0.003232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5]: Train Loss: 0.1757, Train Acc: 0.9295 | Val Loss: 0.3633, Val Acc: 0.8657, Val Recall: 0.9512, Val F1: 0.8966\n",
      "[INFO] No improvement in val_recall. Patience: 4/5\n",
      "[INFO] Learning rate adjusted to: 0.001616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-18 19:07:41,784] Trial 5 finished with value: 0.926829268292683 and parameters: {'lr': 0.0032323398781456242, 'weight_decay': 3.336140015073433e-05, 'optimizer': 'SGD'}. Best is trial 1 with value: 0.9552845528455285.\n",
      "C:\\Users\\Yash\\Documents\\Development\\Projects\\final_year\\env\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Yash\\Documents\\Development\\Projects\\final_year\\env\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "C:\\Users\\Yash\\Documents\\Development\\Projects\\final_year\\env\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6]: Train Loss: 0.1510, Train Acc: 0.9380 | Val Loss: 0.2883, Val Acc: 0.9005, Val Recall: 0.9268, Val F1: 0.9194\n",
      "[INFO] No improvement in val_recall. Patience: 5/5\n",
      "[INFO] Learning rate adjusted to: 0.001616\n",
      "[INFO] Training stopped after 6 epochs.\n",
      "\n",
      "[INFO] Training completed!\n",
      "[INFO] Trial 5 - Final Validation Recall: 0.9268\n",
      "[DEBUG] Starting trial 6...\n",
      "[DEBUG] Suggested hyperparameters: lr=0.00028197726241951536, weight_decay=0.0004760098535780993, optimizer=Adam\n",
      "[DEBUG] Initializing mobilenet_v2 model...\n",
      "[DEBUG] Setting up optimizer...\n",
      "[INFO] Starting model training...\n",
      "\n",
      "Starting training...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1]: Train Loss: 0.3991, Train Acc: 0.8177 | Val Loss: 0.3575, Val Acc: 0.8308, Val Recall: 0.9350, Val F1: 0.8712\n",
      "[INFO] Best model saved with val_recall: 0.9350\n",
      "[INFO] Learning rate adjusted to: 0.000282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2]: Train Loss: 0.2361, Train Acc: 0.9036 | Val Loss: 0.3424, Val Acc: 0.8483, Val Recall: 0.8984, Val F1: 0.8787\n",
      "[INFO] No improvement in val_recall. Patience: 1/5\n",
      "[INFO] Learning rate adjusted to: 0.000282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3]: Train Loss: 0.2097, Train Acc: 0.9210 | Val Loss: 0.2920, Val Acc: 0.8905, Val Recall: 0.9350, Val F1: 0.9127\n",
      "[INFO] No improvement in val_recall. Patience: 2/5\n",
      "[INFO] Learning rate adjusted to: 0.000282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4]: Train Loss: 0.1870, Train Acc: 0.9263 | Val Loss: 0.2839, Val Acc: 0.8930, Val Recall: 0.9390, Val F1: 0.9149\n",
      "[INFO] Best model saved with val_recall: 0.9390\n",
      "[INFO] Learning rate adjusted to: 0.000282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5]: Train Loss: 0.1852, Train Acc: 0.9263 | Val Loss: 0.2924, Val Acc: 0.9005, Val Recall: 0.9146, Val F1: 0.9184\n",
      "[INFO] No improvement in val_recall. Patience: 1/5\n",
      "[INFO] Learning rate adjusted to: 0.000282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6]: Train Loss: 0.1441, Train Acc: 0.9428 | Val Loss: 0.3981, Val Acc: 0.8582, Val Recall: 0.9553, Val F1: 0.8918\n",
      "[INFO] Best model saved with val_recall: 0.9553\n",
      "[INFO] Learning rate adjusted to: 0.000282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7]: Train Loss: 0.1307, Train Acc: 0.9465 | Val Loss: 0.3078, Val Acc: 0.8881, Val Recall: 0.9228, Val F1: 0.9098\n",
      "[INFO] No improvement in val_recall. Patience: 1/5\n",
      "[INFO] Learning rate adjusted to: 0.000282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8]: Train Loss: 0.1103, Train Acc: 0.9560 | Val Loss: 0.3177, Val Acc: 0.9030, Val Recall: 0.9593, Val F1: 0.9237\n",
      "[INFO] Best model saved with val_recall: 0.9593\n",
      "[INFO] Learning rate adjusted to: 0.000282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9]: Train Loss: 0.1221, Train Acc: 0.9507 | Val Loss: 0.2258, Val Acc: 0.9104, Val Recall: 0.9309, Val F1: 0.9271\n",
      "[INFO] No improvement in val_recall. Patience: 1/5\n",
      "[INFO] Learning rate adjusted to: 0.000282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10]: Train Loss: 0.1060, Train Acc: 0.9587 | Val Loss: 0.3488, Val Acc: 0.8980, Val Recall: 0.9472, Val F1: 0.9191\n",
      "[INFO] No improvement in val_recall. Patience: 2/5\n",
      "[INFO] Learning rate adjusted to: 0.000282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11]: Train Loss: 0.0933, Train Acc: 0.9666 | Val Loss: 0.3071, Val Acc: 0.9104, Val Recall: 0.9553, Val F1: 0.9289\n",
      "[INFO] No improvement in val_recall. Patience: 3/5\n",
      "[INFO] Learning rate adjusted to: 0.000282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12]: Train Loss: 0.1157, Train Acc: 0.9576 | Val Loss: 0.2834, Val Acc: 0.9080, Val Recall: 0.9350, Val F1: 0.9256\n",
      "[INFO] No improvement in val_recall. Patience: 4/5\n",
      "[INFO] Learning rate adjusted to: 0.000141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-18 19:09:47,973] Trial 6 finished with value: 0.959349593495935 and parameters: {'lr': 0.00028197726241951536, 'weight_decay': 0.0004760098535780993, 'optimizer': 'Adam'}. Best is trial 6 with value: 0.959349593495935.\n",
      "C:\\Users\\Yash\\Documents\\Development\\Projects\\final_year\\env\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Yash\\Documents\\Development\\Projects\\final_year\\env\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "C:\\Users\\Yash\\Documents\\Development\\Projects\\final_year\\env\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13]: Train Loss: 0.0775, Train Acc: 0.9751 | Val Loss: 0.2349, Val Acc: 0.9279, Val Recall: 0.9593, Val F1: 0.9421\n",
      "[INFO] No improvement in val_recall. Patience: 5/5\n",
      "[INFO] Learning rate adjusted to: 0.000141\n",
      "[INFO] Training stopped after 13 epochs.\n",
      "\n",
      "[INFO] Training completed!\n",
      "[INFO] Trial 6 - Final Validation Recall: 0.9593\n",
      "[DEBUG] Starting trial 7...\n",
      "[DEBUG] Suggested hyperparameters: lr=0.004255450414076736, weight_decay=0.0006437536330638324, optimizer=AdamW\n",
      "[DEBUG] Initializing mobilenet_v2 model...\n",
      "[DEBUG] Setting up optimizer...\n",
      "[INFO] Starting model training...\n",
      "\n",
      "Starting training...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1]: Train Loss: 0.6714, Train Acc: 0.7011 | Val Loss: 0.9276, Val Acc: 0.5373, Val Recall: 0.2764, Val F1: 0.4224\n",
      "[INFO] Best model saved with val_recall: 0.2764\n",
      "[INFO] Learning rate adjusted to: 0.004255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2]: Train Loss: 0.5049, Train Acc: 0.7536 | Val Loss: 0.5379, Val Acc: 0.7338, Val Recall: 0.7520, Val F1: 0.7757\n",
      "[INFO] Best model saved with val_recall: 0.7520\n",
      "[INFO] Learning rate adjusted to: 0.004255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3]: Train Loss: 0.6066, Train Acc: 0.7361 | Val Loss: 0.5714, Val Acc: 0.7289, Val Recall: 0.8171, Val F1: 0.7867\n",
      "[INFO] Best model saved with val_recall: 0.8171\n",
      "[INFO] Learning rate adjusted to: 0.004255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4]: Train Loss: 0.4759, Train Acc: 0.7785 | Val Loss: 0.5032, Val Acc: 0.7363, Val Recall: 0.8089, Val F1: 0.7897\n",
      "[INFO] No improvement in val_recall. Patience: 1/5\n",
      "[INFO] Learning rate adjusted to: 0.004255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5]: Train Loss: 0.4233, Train Acc: 0.7944 | Val Loss: 0.5248, Val Acc: 0.7438, Val Recall: 0.7846, Val F1: 0.7894\n",
      "[INFO] No improvement in val_recall. Patience: 2/5\n",
      "[INFO] Learning rate adjusted to: 0.004255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6]: Train Loss: 0.3865, Train Acc: 0.8209 | Val Loss: 0.6426, Val Acc: 0.7612, Val Recall: 0.7480, Val F1: 0.7931\n",
      "[INFO] No improvement in val_recall. Patience: 3/5\n",
      "[INFO] Learning rate adjusted to: 0.004255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7]: Train Loss: 0.4118, Train Acc: 0.8039 | Val Loss: 0.4825, Val Acc: 0.7463, Val Recall: 0.9187, Val F1: 0.8159\n",
      "[INFO] Best model saved with val_recall: 0.9187\n",
      "[INFO] Learning rate adjusted to: 0.004255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8]: Train Loss: 0.4205, Train Acc: 0.8135 | Val Loss: 0.6651, Val Acc: 0.7239, Val Recall: 0.6707, Val F1: 0.7483\n",
      "[INFO] No improvement in val_recall. Patience: 1/5\n",
      "[INFO] Learning rate adjusted to: 0.004255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9]: Train Loss: 0.4082, Train Acc: 0.8241 | Val Loss: 0.4475, Val Acc: 0.7910, Val Recall: 0.8943, Val F1: 0.8397\n",
      "[INFO] No improvement in val_recall. Patience: 2/5\n",
      "[INFO] Learning rate adjusted to: 0.004255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10]: Train Loss: 0.3661, Train Acc: 0.8453 | Val Loss: 0.4243, Val Acc: 0.7836, Val Recall: 0.9065, Val F1: 0.8368\n",
      "[INFO] No improvement in val_recall. Patience: 3/5\n",
      "[INFO] Learning rate adjusted to: 0.004255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11]: Train Loss: 0.3806, Train Acc: 0.8352 | Val Loss: 0.3878, Val Acc: 0.8159, Val Recall: 0.9309, Val F1: 0.8609\n",
      "[INFO] Best model saved with val_recall: 0.9309\n",
      "[INFO] Learning rate adjusted to: 0.004255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2024-12-18 19:11:44,512] Trial 7 failed with parameters: {'lr': 0.004255450414076736, 'weight_decay': 0.0006437536330638324, 'optimizer': 'AdamW'} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Yash\\Documents\\Development\\Projects\\final_year\\env\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Yash\\AppData\\Local\\Temp\\ipykernel_10436\\3609394824.py\", line 33, in objective\n",
      "    history = train_model(\n",
      "              ^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Yash\\Documents\\Development\\Projects\\final_year\\utils\\train_utils.py\", line 68, in train_model\n",
      "    train_loss += loss.item() * images.size(0)\n",
      "                  ^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "[W 2024-12-18 19:11:44,538] Trial 7 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[INFO] Running hyperparameter optimization...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[INFO] Best parameters found: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstudy\u001b[38;5;241m.\u001b[39mbest_params\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\Documents\\Development\\Projects\\final_year\\env\\Lib\\site-packages\\optuna\\study\\study.py:475\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    373\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[0;32m    374\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    375\u001b[0m     func: ObjectiveFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    382\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    383\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    384\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[0;32m    385\u001b[0m \n\u001b[0;32m    386\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    473\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[0;32m    474\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 475\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    476\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    477\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    478\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    479\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    480\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    481\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    483\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    485\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Documents\\Development\\Projects\\final_year\\env\\Lib\\site-packages\\optuna\\study\\_optimize.py:63\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 63\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     76\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32m~\\Documents\\Development\\Projects\\final_year\\env\\Lib\\site-packages\\optuna\\study\\_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    157\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 160\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[0;32m    164\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[0;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[1;32m~\\Documents\\Development\\Projects\\final_year\\env\\Lib\\site-packages\\optuna\\study\\_optimize.py:248\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    241\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    244\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[0;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    246\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[0;32m    247\u001b[0m ):\n\u001b[1;32m--> 248\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[1;32m~\\Documents\\Development\\Projects\\final_year\\env\\Lib\\site-packages\\optuna\\study\\_optimize.py:197\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[0;32m    196\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 197\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    198\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    199\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[0;32m    200\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[1;32mIn[6], line 33\u001b[0m, in \u001b[0;36mobjective\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[INFO] Starting model training...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     32\u001b[0m save_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs/models/mobilenet_v2_trial_best.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 33\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     40\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     42\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stop_patience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     43\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmonitor_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mval_recall\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     44\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[INFO] Training completed!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     47\u001b[0m \u001b[38;5;66;03m# Return validation recall\u001b[39;00m\n",
      "File \u001b[1;32m~\\Documents\\Development\\Projects\\final_year\\utils\\train_utils.py:68\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, train_loader, val_loader, criterion, optimizer, scheduler, device, save_path, early_stop_patience, monitor_metric, max_epochs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     66\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m---> 68\u001b[0m     train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m*\u001b[39m images\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     69\u001b[0m     train_correct \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (outputs\u001b[38;5;241m.\u001b[39margmax(\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m==\u001b[39m labels)\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m     71\u001b[0m train_loss \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_loader\u001b[38;5;241m.\u001b[39mdataset)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Run Optuna\n",
    "print(\"[INFO] Running hyperparameter optimization...\")\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=20)\n",
    "print(f\"[INFO] Best parameters found: {study.best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Final Model\n",
    "print(\"[INFO] Training final model with best hyperparameters...\")\n",
    "final_model = initialize_model(\"mobilenet_v2\", num_classes=2, pretrained=True, freeze_all=False, unfreeze_last_n=2)\n",
    "final_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer\n",
    "optimizer = optim.Adam(final_model.parameters(), lr=study.best_params[\"lr\"], weight_decay=study.best_params[\"weight_decay\"])\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"max\", patience=3, factor=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final training\n",
    "final_save_path = \"outputs/models/mobilenet_v2_final.pth\"\n",
    "history = train_model(\n",
    "    model=final_model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    criterion=nn.CrossEntropyLoss(),\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    device=device,\n",
    "    save_path=final_save_path,\n",
    "    early_stop_patience=5,\n",
    "    monitor_metric=\"val_recall\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation and Visualization\n",
    "print(\"[INFO] Evaluating final model...\")\n",
    "metrics = evaluate_model(final_model, test_loader, [\"No Fire\", \"Fire\"], device)\n",
    "plot_training(history, \"outputs/plots/mobilenet_v2_training_curve.png\")\n",
    "plot_confusion_matrix(metrics[\"confusion_matrix\"], [\"No Fire\", \"Fire\"], \"outputs/plots/mobilenet_v2_confusion_matrix.png\")\n",
    "print(\"[INFO] Final results saved successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
